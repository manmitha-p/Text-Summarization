{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b30bc6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T17:12:11.320621Z",
     "iopub.status.busy": "2024-01-13T17:12:11.320241Z",
     "iopub.status.idle": "2024-01-13T17:12:39.889357Z",
     "shell.execute_reply": "2024-01-13T17:12:39.888489Z"
    },
    "papermill": {
     "duration": 28.576808,
     "end_time": "2024-01-13T17:12:39.891756",
     "exception": false,
     "start_time": "2024-01-13T17:12:11.314948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287113"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train=pd.read_csv(\"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv\")\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "388cc72d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T17:12:39.900126Z",
     "iopub.status.busy": "2024-01-13T17:12:39.899821Z",
     "iopub.status.idle": "2024-01-13T17:12:40.023240Z",
     "shell.execute_reply": "2024-01-13T17:12:40.022339Z"
    },
    "papermill": {
     "duration": 0.129716,
     "end_time": "2024-01-13T17:12:40.025197",
     "exception": false,
     "start_time": "2024-01-13T17:12:39.895481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            0\n",
       "article       0\n",
       "highlights    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71ef5914",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T17:12:40.035188Z",
     "iopub.status.busy": "2024-01-13T17:12:40.034504Z",
     "iopub.status.idle": "2024-01-13T17:12:40.039869Z",
     "shell.execute_reply": "2024-01-13T17:12:40.039039Z"
    },
    "papermill": {
     "duration": 0.012762,
     "end_time": "2024-01-13T17:12:40.041780",
     "exception": false,
     "start_time": "2024-01-13T17:12:40.029018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training=train['article'][:200].replace(\"'\", \"\")\n",
    "testing=train['highlights'][:200].replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4e3d6a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T17:12:40.051526Z",
     "iopub.status.busy": "2024-01-13T17:12:40.051233Z",
     "iopub.status.idle": "2024-01-13T17:12:58.563246Z",
     "shell.execute_reply": "2024-01-13T17:12:58.562238Z"
    },
    "papermill": {
     "duration": 18.519927,
     "end_time": "2024-01-13T17:12:58.565491",
     "exception": false,
     "start_time": "2024-01-13T17:12:40.045564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/tmp/ipykernel_26/1899618636.py:11: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  training=training.apply(tokenizenews,tokenizer)\n",
      "/tmp/ipykernel_26/1899618636.py:12: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  testing=testing.apply(tokenizenews,tokenizer)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tokenizer=tf.keras.preprocessing.text.Tokenizer()\n",
    "\n",
    "def tokenizenews(random_sentence):\n",
    "#     tokenizer=tf.keras.preprocessing.text.Tokenizer()\n",
    "    tokenizer.fit_on_texts([random_sentence])\n",
    "    sequence = tokenizer.texts_to_sequences([random_sentence])\n",
    "    sequence_length = 50  \n",
    "    padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=sequence_length)\n",
    "    return padded_sequence\n",
    "training=training.apply(tokenizenews,tokenizer)\n",
    "testing=testing.apply(tokenizenews,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4353dcd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T17:12:58.576074Z",
     "iopub.status.busy": "2024-01-13T17:12:58.575283Z",
     "iopub.status.idle": "2024-01-13T17:13:07.538807Z",
     "shell.execute_reply": "2024-01-13T17:13:07.537847Z"
    },
    "papermill": {
     "duration": 8.971258,
     "end_time": "2024-01-13T17:13:07.540989",
     "exception": false,
     "start_time": "2024-01-13T17:12:58.569731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "vocab_size = 10000\n",
    "embedding_dim = 200\n",
    "encoder_hidden_states=[]\n",
    "sequence_length = 50\n",
    "input_sequence = tf.keras.Input(shape=(sequence_length, ))\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_sequence)\n",
    "encoder_lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(1600 , return_sequences=True))(embedding_layer)\n",
    "encoded_representation = tf.keras.layers.Concatenate()([encoder_lstm[:, -1, :], encoder_lstm[:, 0, :]])\n",
    "model = tf.keras.Model(inputs=input_sequence, outputs=encoded_representation )\n",
    "def encoder(array,testarray,model):\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    for i in range(len(array)):\n",
    "        with tf.GradientTape() as tape:\n",
    "            result = model(array[i],training=True)\n",
    "            testresult=model(testarray[i],training=True)\n",
    "            loss = tf.keras.losses.mean_squared_error(result, testresult)\n",
    "#             print(result.shape,testresult.shape,loss)\n",
    "            encoder_hidden_states.append(result)\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return encoder_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e303a7b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T17:13:07.550832Z",
     "iopub.status.busy": "2024-01-13T17:13:07.550472Z",
     "iopub.status.idle": "2024-01-13T17:13:07.567302Z",
     "shell.execute_reply": "2024-01-13T17:13:07.566434Z"
    },
    "papermill": {
     "duration": 0.024197,
     "end_time": "2024-01-13T17:13:07.569412",
     "exception": false,
     "start_time": "2024-01-13T17:13:07.545215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decoder(encoder_hidden_states,target_tokens,model1):\n",
    "    loss = 0\n",
    "    context_vector = None\n",
    "    decoder_state = None\n",
    "    sequence_length = 50\n",
    "    hidden_size = 128\n",
    "    embedding_dim = 128\n",
    "    vocab_size = 10000\n",
    "    context_vector=tf.zeros((128,50 ))\n",
    "    decoder_state=tf.zeros((128, 50))\n",
    "    learning_rate=0.001\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    v = tf.random.normal(shape=(hidden_size,50))\n",
    "    Wh = tf.random.normal(shape=(hidden_size, 50))\n",
    "    Ws = tf.random.normal(shape=(hidden_size, 50))\n",
    "    battn = tf.random.normal(shape=(hidden_size,50))\n",
    "    weights= tf.random.normal(shape=(100, 1))   \n",
    "    bias=tf.random.uniform([]) \n",
    "    for t in range(len(target_tokens)):\n",
    "        input_sequence = tf.keras.Input(shape=(sequence_length, ))\n",
    "        embedding_layer = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_sequence)\n",
    "#         LSTM=tf.keras.layers.LSTM(128,return_sequences=True)(embedding_layer)\n",
    "        model = tf.keras.Model(inputs=input_sequence, outputs=embedding_layer)\n",
    "        output_embeddings = model.predict(target_tokens[t],verbose=0)\n",
    "        attention_scores = []\n",
    "        for i in range(len(encoder_hidden_states)):\n",
    "            encoder_hidden_states[i] = tf.reshape(encoder_hidden_states[i], (128,50))\n",
    "            e_t_i = v * tf.nn.tanh(Wh * encoder_hidden_states[i]+ Ws*decoder_state+  battn)\n",
    "            attention_scores.append(e_t_i)\n",
    "        attention_distributon=tf.nn.softmax(attention_scores)\n",
    "        for i in range(len(encoder_hidden_states)):\n",
    "            context_vector += attention_distributon[i] * encoder_hidden_states[i]\n",
    "        output_embeddings=tf.reshape(output_embeddings, (128, 50, 1))\n",
    "        output_embeddings=tf.squeeze(output_embeddings, axis=-1)\n",
    "        concatenated_input = tf.expand_dims(tf.concat([context_vector,output_embeddings], axis=-1),axis=0)\n",
    "        output_embeddings1=tf.matmul(concatenated_input,weights)+bias\n",
    "        vocab_distribution=tf.nn.softmax(output_embeddings1,axis=1)\n",
    "        highest_prob_index=np.argmax(vocab_distribution)\n",
    "#         print(highest_prob_index)\n",
    "        target_word_prob = vocab_distribution[0,highest_prob_index,0]\n",
    "        timestep_loss = -tf.math.log(target_word_prob)\n",
    "        decoder_state=(decoder_state+context_vector)/2\n",
    "        decoder_state = tf.reshape(decoder_state, (128, 50))\n",
    "#         print(timestep_loss)\n",
    "        loss += timestep_loss\n",
    "        meanloss=loss/(t+1)\n",
    "        #optimization process\n",
    "        v+=learning_rate*meanloss* tf.nn.tanh(Wh * encoder_hidden_states[i]+ Ws*decoder_state+  battn)\n",
    "        Ws+=learning_rate*meanloss*decoder_state\n",
    "        Wh=Wh+learning_rate*meanloss*encoder_hidden_states[i]\n",
    "        battn+=learning_rate*meanloss\n",
    "        bias+=learning_rate*meanloss\n",
    "        weights+=learning_rate*meanloss*weights\n",
    "        decoder_state=(decoder_state+context_vector)/2\n",
    "        decoder_state = tf.reshape(decoder_state, (128, 50))\n",
    "    return [v,Ws,Wh,battn,weights,bias]\n",
    "#         print(v,Ws,Wh,battn,decoder_state,model1.trainable_variables)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bcd6dc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T17:13:07.578384Z",
     "iopub.status.busy": "2024-01-13T17:13:07.578100Z",
     "iopub.status.idle": "2024-01-13T17:14:40.119010Z",
     "shell.execute_reply": "2024-01-13T17:14:40.117994Z"
    },
    "papermill": {
     "duration": 92.550895,
     "end_time": "2024-01-13T17:14:40.124409",
     "exception": false,
     "start_time": "2024-01-13T17:13:07.573514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.engine.functional.Functional object at 0x7b9893f99c30>\n"
     ]
    }
   ],
   "source": [
    "encoder_hidden=encoder(training,testing,model)\n",
    "input_sequence1 = tf.keras.Input(shape=(128, 100))\n",
    "layer2=tf.keras.layers.Dense(1)(input_sequence1)\n",
    "model1 = tf.keras.Model(inputs=input_sequence1, outputs=layer2)\n",
    "v,Ws,Wh,battn,weights,bias=decoder(encoder_hidden,testing,model1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b908d58a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T17:14:40.134202Z",
     "iopub.status.busy": "2024-01-13T17:14:40.133772Z",
     "iopub.status.idle": "2024-01-13T17:14:40.147978Z",
     "shell.execute_reply": "2024-01-13T17:14:40.147097Z"
    },
    "papermill": {
     "duration": 0.021461,
     "end_time": "2024-01-13T17:14:40.149868",
     "exception": false,
     "start_time": "2024-01-13T17:14:40.128407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tests(para,v,Ws,Wh,battn,weights,model,bias,tokenizer,length=50):\n",
    "#     tokenizer=tf.keras.preprocessing.text.Tokenizer()\n",
    "    tokenizer.fit_on_texts([para])\n",
    "    sequence = tokenizer.texts_to_sequences([para])\n",
    "    sequence_length = 50  # Adjust as needed\n",
    "    padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=sequence_length)\n",
    "    tokenspara=tokenizenews(para)\n",
    "    encoder_hidden_states=[model.predict(tokenspara)]\n",
    "    summary=[]\n",
    "    sequence_length = 50\n",
    "    hidden_size = 128\n",
    "    embedding_dim = 50\n",
    "    context_vector=tf.zeros((128,50 ))\n",
    "    decoder_state=tf.zeros((128, 50))\n",
    "    current_token = np.zeros((128,))\n",
    "    for j in range(length):\n",
    "        input_sequence = tf.keras.Input(shape=(sequence_length, ))\n",
    "        embedding_layer = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_sequence)\n",
    "        model = tf.keras.Model(inputs=input_sequence, outputs=embedding_layer)\n",
    "        output_embeddings = model.predict(current_token,verbose=0)\n",
    "        attention_scores = []\n",
    "        for i in range(len(encoder_hidden_states)):\n",
    "            encoder_hidden_states[i] = tf.reshape(encoder_hidden_states[i], (128,50))\n",
    "            e_t_i = v * tf.nn.tanh(Wh * encoder_hidden_states[i]+ Ws*decoder_state+  battn)\n",
    "            attention_scores.append(e_t_i)\n",
    "        attention_distributon=tf.nn.softmax(attention_scores)\n",
    "        for i in range(len(encoder_hidden_states)):\n",
    "            context_vector += attention_distributon[i] * encoder_hidden_states[i]\n",
    "        output_embeddings=tf.reshape(output_embeddings, (128, 50, 1))\n",
    "        output_embeddings=tf.squeeze(output_embeddings, axis=-1)\n",
    "        concatenated_input = tf.expand_dims(tf.concat([context_vector,output_embeddings], axis=-1),axis=0)\n",
    "        output_embeddings1=tf.matmul(concatenated_input,weights)+bias\n",
    "        vocab_distribution=tf.nn.softmax(output_embeddings1,axis=1)\n",
    "        highest_prob_index=np.argmax(vocab_distribution)\n",
    "        current_token[j]=highest_prob_index\n",
    "        decoder_state=(decoder_state+context_vector)/2\n",
    "        decoder_state = tf.reshape(decoder_state, (128, 50))\n",
    "        summary.append(current_token)\n",
    "    tokentoword={tokenizer.word_index[i]:i for i in tokenizer.word_index.keys()}\n",
    "    tokentoword.update({0.0:\"\",127.0:\"\"})\n",
    "    return (\" \".join([tokentoword[i] for i in current_token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a17c99b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T17:14:40.158964Z",
     "iopub.status.busy": "2024-01-13T17:14:40.158659Z",
     "iopub.status.idle": "2024-01-13T17:15:27.845614Z",
     "shell.execute_reply": "2024-01-13T17:15:27.844534Z"
    },
    "papermill": {
     "duration": 47.693858,
     "end_time": "2024-01-13T17:15:27.847694",
     "exception": false,
     "start_time": "2024-01-13T17:14:40.153836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the moment that a crew of firefighters struggled to haul a giant  pig out of a garden swimming pool. The prize porker, known  as Pigwig, had fallen into the pool in an upmarket neighbourhood in Ringwood, Hampshire. His owners had been taking him for a walk around the garden when the animal plunged into the water and was unable to get out. A team from Dorset Fire and Rescue struggled to haul the huge black pig out of swimming pool water . The prize porker known as Pigwig had fallen into the water and had then been unable to get out again . Two fire crews and a specialist animal rescue team had to use slide boards and strops to haul the huge black pig from the small pool. A spokesman for Dorset Fire and Rescue Service said: 'At 4.50pm yesterday the service received a call to a pig stuck in a swimming pool. 'One crew of firefighters from Ferndown and a specialist animal rescue unit from Poole were mobilised to this incident. 'Once in attendance the crew secured the pig with strops, and requested the attendance of another appliance which was mobilised from Ringwood by our colleagues in Hampshire Fire and Rescue Service. Firefighters were also called out to a horse which had fallen into a swimming pool in Heyshott, West Sussex . The exhausted animal had to be winched to using an all-terrain crane but appeared no worse for wear after its tumble . 'The crew rescued the pig from the swimming pool using specialist animal rescue slide boards, strops and lines to haul the pig from the swimming pool.' But Pigwig wasn't the only animal who needed rescuing after taking an unexpected swim . Crews in West Sussex were called out to a swimming pool where this time a horse had fallen in. Wet and very bedraggled, the exhausted animal put up no opposition when firefighters arrived to hoist her out of the small garden pool in Heyshott. The two-hour rescue operation ended with the wayward horse being fitted with straps under her belly and lifted up into the air with an all-terrain crane before being swung around and deposited back on dry land. A fire brigade spokesman said that she appeared none the worse for her impromptu swim after stepping over the edge of the domestic pool.\n",
      "\n",
      "1/1 [==============================] - 1s 678ms/step\n",
      "and and and to and a a and in are a and are a in a are a was and a with be and as a was by and a they and and have a be by not be was and not be this and this one they by with not one with their with with all was and all mr a and a and and by and with with  one a and what and by and all a and and with by by their by and could with and like what and and with and with and what                            \n",
      "\n",
      "The amount of time people spend listening to BBC radio has dropped to its lowest level ever, the corporation’s boss has admitted. Figures show that while millions still tune in, they listen for much shorter bursts. The average listener spent just ten hours a week tuning in to BBC radio in the last three months of 2014, according to official figures. The length of time people spend listening to BBC radio has dropped to its lowest level ever, figures show . This was 14 per cent down on a decade earlier, when listeners clocked up an average of 11.6 hours a week. The minutes of the BBC Trust’s February meeting, published yesterday, revealed that director general Tony Hall highlighted the fall. ‘He noted…that time spent listening to BBC radio had dropped to its lowest ever level,’ the documents said. Sources blamed the downward trend on people leading faster-paced lives than in the past, and a change in habits amongst young people. Lord Tony Hall, BBC director general, highlighted the decline to the BBC Trust, according to minutes of its February meeting . Many people who used to listen to radio as a daily habit now turn to online streaming services such as Spotify for their music fix. That problem is likely to grow, as Apple develops its long-rumoured streaming service. A BBC spokesman said: ‘The number of people listening to BBC radio stations and audience appreciation levels are as high as ever. ‘But time spent listening has inevitably been affected by digital competition and as people ‘tune in’ in new, digital ways. ‘[Those ways] aren’t reflected in the traditional listening figures quoted here – like watching videos from radio shows or listening to podcasts.’ BBC radio is still reaching 65 per cent of the population each week, according to the last set of figures available from RAJAR, the organisation which measures radio audiences. But although that figure feels relatively healthy by today’s standards, it has none the less fallen by more over the last decade. In the final three months of 2004, 66 per cent of people in Britain listened to BBC network radio every week. Lord Hall also used the BBC Trust meeting to note the strong performance of BBC Radio 6, the digital music station which the Corporation had at one point been planning to scrap. ‘He reported that the recent RAJAR figures showed that 6Music had become the first digital-only station to reach two million listeners,’ the minutes said. Earlier this month, Matthew Postgate, the BBC’s chief technology officer, said the Corporation would adopt a new ‘digital first’ strategy, to help it target a new generation of users. He said the organisation needed to ‘learn lessons’ if they want to ‘compete with organisations that were born in the digital age’.\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "and and  and a and and and and with with a with a with  and and and a with  with and be are with and and with and       and and and has be  and with and are which  are with and and with and be and  with  and which with and be  into into  are are and people but and  are but are and  and  are with are and and if people and with with says  and into  and with                            \n",
      "\n",
      "(CNN)So, you'd like a \"Full House\" reunion and spinoff? You got it, dude! Co-star John Stamos announced Monday night on \"Jimmy Kimmel Live\" that Netflix has ordered up a reunion special, followed by a spinoff series called \"Fuller House.\" The show will feature Candace Cameron Bure, who played eldest daughter D.J. Tanner in the original series -- which aired from 1987 to 1995 -- as the recently widowed mother of three boys. \"It's sort of a role reversal, and we turn the house over to her,\" Stamos told Kimmel. Jodie Sweetin, who played Stephanie Tanner in the original series, and Andrea Barber, who portrayed D.J.'s best friend Kimmy Gibbler, will both return for the new series, Netflix said. Stamos will produce and guest star. Talks with co-starsBob Saget, Mary-Kate and Ashley Olsen, Dave Coulier and Lori Loughlin are ongoing, Netflix said. The show will be available next year, Netflix said. \"As big fans of the original Full House, we are thrilled to be able to introduce Fuller House's new narrative to existing fans worldwide, who grew up on the original, as well as a new generation of global viewers that have grown up with the Tanners in syndication,\"  Netflix Vice President of Original Content Cindy Holland said in a statement. The show starts with Tanner -- now named Tanner-Fuller (get it ... Fuller?) -- pregnant, recently widowed and living in San Francisco. Her younger sister Stephanie -- now an aspiring musician -- and her lifelong best friend and fellow single mom, Kimmy, move in to help her care for her two boys and the new baby. On Monday, Barber tweeted Cameron Bure to ask whether she was ready to resume their onscreen friendship. \"We never stopped,\" Cameron Bure tweeted back. Fans were over the moon at the news.\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "and and and and to are of in to of are of in are are and in and are in with by in in  and  are  be her and  but by  and  be in   her by are and  been  are ' and her and  and but but it by by and it  about by and are her   and and and and are by by it are by and been and and and and and by are  and and  and and  and in and                            \n",
      "\n",
      "At 11:20pm, former world champion Ken Doherty potted a final black and extinguished, for now, the dream of Reanne Evans to become the first women player to play the hallowed baize of Sheffield's Crucible Theatre in the world snooker championship. In every other respect however, 29-year-old Evans, a single mum from Dudley, was a winner on Thursday night. She advanced the cause of women in sport no end and gave Doherty the fright of his life in an enthralling and attritional match that won't be bettered in this year's qualifying tournament. Snooker's governing body had been criticised in some quarters for allowing Evans a wild card to compete alongside 127 male players for the right to play in the sport's blue-chip event on April 18 - something no female had achieved. Reanne Evans shakes hands with Ken Doherty following his 10-8 victory at Ponds Forge . Evans plays a shot during her world championship qualifying match against Doherty . Doherty, who won the World Championship title back in 1997, took out the first frame 71-15 . Evans had Doherty in all sorts of trouble before the former champion closed out the game 10-8 . Those critics and the bookies who made Doherty a ridiculously short-priced 20/1 on favourite were made to look foolish as Evans had her illustrious opponent on the ropes before finally bowing out 10-8. A gracious Doherty admitted afterwards: 'She played out of her skin. It was good match play snooker and tough all the way through. There was a lot of pressure on this match, a different kind of pressure to what I've ever experienced. 'I don't usually feel sympathy for my opponents but I felt sorry at the end. She played better than me and lost. I don't know how I won that final frame. If it had gone to 9-9, I'd have been a million-to-one to win it.' Evans, cheered on by her eight-year-old daughter Lauren at the Ponds Forge sports centre in Sheffield, admitted she was exhausted after a match of unfamiliar intensity for her. A 10-time ladies' champion, Evans had led twice during the opening session before Doherty went 5-4 in front . The 10-time ladies world champion collected just £400 as prize money for winning the title in 2013, and this was a completely different environment against a player who beat Stephen Hendry to be crowned the best player in the world in 1997. 'It was a struggle. With the experience Ken had, I just had to dig in,' she said. 'Ken had little runs when he needed it but I could tell he was under pressure. Some of the balls were wobbling in from the first frame. I just couldn't take advantage in the end. 'I can play better than I did so there is no reason I can't return and beat Ken or even players above him. I have the women's game on my shoulders. I just hope I get some help and am allowed to play in more big tournaments to give me experience. 'Next week, I will playing the ladies in the club again. It's a lovely club don't get me wrong but I don't think many ladies could give Ken a game. I think I would have won if I'd taken it to 9-9.' The presence of television crews and snooker star Ronnie O'Sullivan underlined what a big story Evans' participation was. Evans eyes up her move during an enthralling game with Doherty in Sheffield . She lost the first frame convincingly but the nerves didn't show after that. She reeled off three frames in a row, led 4-3 and once Doherty went in front, pegged him back to 5-5 and 6-6. The Irishman, now ranked No 46 in the world, started to look his 45 years. He sat down at every opportunity while Evans often stood while he played. She had the confidence to play right-handed or left-handed, as O'Sullivan sometimes does. The key frame was the sixteenth. It lasted 45 minutes with Evans rattling off the first 59 points and Doherty the next 74. It took Doherty to a 9-7 lead but Evans came roaring back in the next frame. He needed a snooker to avoid the match going into a final frame – and he got it. Doherty, now ranked No 46 in the world, showed his experience to close out the contest . He has two more qualifying rounds before he makes the Crucible but it's doubtful he will face a tougher opponent. 'They should let her play in more competitions,' he added. Evans should certainly use this match to become a leading ambassador for women's sport. Her purple and silver waistcoats drew admiring glances from the swimmers and trampolinists who turned up at the leisure centre as normal as she walked through reception to the basketball hall, where 10 snooker tables had been set up. Next time they will know exactly who she is, and what she can do.\n",
      "\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "and and  and and and and are are was for and was he was and and that and as and that are was from from but are are from and be and and are are but and and had be around are which and from and but are was will and with and are was and and and were around that with from and are and and and there and into from but and are around and and and around and and was but and around and and around and are will from are are are and and around                            \n",
      "\n",
      "A gang of six men have been jailed for a total of 31 years after being convicted of a string of sexual offences against teenager girls. The offences, which ranged from inciting sexual activity with a child, to rape, happened in cars, woods or at the defendants' homes in Banbury, Oxfordshire. Oxford Crown Court heard how they lured victims to parties organised on social media and then began sexually abusing them. The men were found guilty in March and have now been handed sentences of between three and nine years in jail. Jailed: Ahmed Hassan-Sule, 21 (left) was sentenced to nine years' imprisonment. Mohamed Saleh, 22, (right) was imprisoned for four years and nine months . The girls, aged between 13 and 16, were targeted by the gang  at under-18s parties organised by Ahmed Hassan-Sule, 21, known as 'Fiddy'. One child described the parties as 'a place where girls would go and the boys would choose their targets'. The victims, who were described in court as 'emotionally immature' were abused from 2009 to 2014. Sentencing Hassan-Sule and the others in a court packed with friends and relatives of the defendants and victims yesterday, Judge Zoe Smith said: 'You put on charity events to raise money for your football club. 'This raised your profile among young people in Banbury and you saw yourself as a celebrity. 'Your friends helped put on these events and you became a sexually promiscuous group, not with your own girlfriends, but with girls who were young, vulnerable and lacking in maturity.' The judge rejected the argument put forward by the defence, who accused the girls of coming forward because 'it's better to be a victim than a slag'. Behind bars: Kagiso Manase, 26, (left) was jailed for four years and Said Saleh, 20, (right) was sentenced to four years' detention in a Young Offenders Institute . One of the victims told the Oxford Mail: 'When I used to go missing I would swear at my mum and I didn't realise I was being really nasty to her. The men put me against my family – it was really clever. When I started hanging around with them I felt important. 'I had no friends and they were the only people left to talk to. It was a big part of my life and I was scared. I felt like all my friends were making new memories and I wasn't part of them. 'Calling people \"slags\" as the defence did in this case stops other girls from coming forward. I would say to other girls to think about the future. I never wanted to do it. I never wanted to have sex with them but I thought that's what friends did.' Thames Valley Police launched Operation Reportage after receiving a tip-off about the men's activities and eventually tracked down numerous teenager girls who had been molested. Detective Inspector Steve Raffield from Banbury Force CID said: 'This result would not have been possible without the bravery of the victims. 'I would like to thank them for coming forward and giving evidence in this case. As in all trials without their testimony we would not be where we are today. 'As a result young people will be safeguarded while these men will have time to reflect upon their actions in prison.' Convicted: Takudzwa Hova, 21, (left) was sentenced to six years' imprisonment, while Zsolt Szalontai, 18, (right) was sentenced to three years' detention in a Young Offenders' Institute after being found guilty of rape . Justice: The judge rejected the argument put forward by the defence at Oxford Crown Court (pictured), who accused the girls of coming forward because 'it's better to be a victim than a slag' Those jailed on Friday afternoon at Oxford Crown Court were: Ahmed Hassan-Sule, 21, of Banbury, who was found guilty of 13 counts of sexual activity with a child and one count of assault by penetration. He was sentenced to nine years' imprisonment. Mohamed Saleh, 22, of Banbury, was found guilty of two counts of sexual activity with a child. He was sentenced to four years and nine months' imprisonment. Said Saleh, 20, from Banbury, was found guilty of one count of sexual activity with a child. He was sentenced to four years' detention in a Young Offenders Institute. Takudzwa Hova, 21, of Banbury, was found guilty of one count of sexual activity with a child, two counts of causing or inciting a child to engage in sexual activity and one count of rape. He was sentenced to six years' imprisonment. Kagiso Manase, 26, of Banbury, was found guilty of two counts of sexual activity with a child, two counts of causing or inciting a child to engage in sexual activity and one count of sexual assault. He was sentenced to four years' imprisonment. Manase had also pleaded guilty to possession of identity documents with intent. The offence related to being found in possession or control of a false South African passport and UK residence permit. He was sentenced to one year imprisonment to run consecutively. Zsolt Szalontai, 18, of Banbury, was found guilty of one count of rape. He was sentenced to three years' detention in a Young Offenders' Institute.\n",
      "\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "and and  and and and and and are and are are and are and and and are are are from and and are are are are and and your they and and your by your by are this and not and by your are by and by and and this by by we and and and this by are we and by and this this by we and and by and by will this and and and and can and and and and by are told and are and left and we your and and and and are and                            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "testarticle=pd.read_csv(\"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv\")\n",
    "testarticle1=testarticle['article'][5:10].replace(\"'\", \"\")\n",
    "for i in testarticle1:\n",
    "    print(i+'\\n')\n",
    "    print(tests(i,v,Ws,Wh,battn,weights,model,bias,tokenizer,100)+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1654566,
     "sourceId": 2734496,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 203.845108,
   "end_time": "2024-01-13T17:15:31.472370",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-13T17:12:07.627262",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
